{
 "metadata": {
  "name": "",
  "signature": "sha256:95982b3e21afecb987c44a07b03ee44de2790864d6cf9e1bae86fc25dc4ffc51"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Trying to replicate the algorithm described in:\n",
      "\n",
      "[1]B. Gatos, I. Pratikakis, and S. J. Perantonis, \"Adaptive degraded document image binarization\", Pattern Recognition, vol. 39, no. 3, pp. 317\\u2013327, Mar. 2006."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy import misc\n",
      "from scipy import signal\n",
      "from scipy import ndimage\n",
      "from skimage.filter import *\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_img_path = './test_pages/original/VA013RN-0014.jpeg'\n",
      "# flatten=True converts to greyscale when reading img in. \n",
      "test_img = misc.imread(test_img_path, flatten=True)\n",
      "test_img = test_img[400:800,400:800]\n",
      "misc.imsave('./thres_test/original.jpeg', test_img)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Tests of the skimage otsu and adaptive thresholds"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#adapt_thres_img = threshold_adaptive(test_img, 47)\n",
      "otsu_thres_val = threshold_otsu(test_img)\n",
      "otsu_thres_img = test_img > otsu_thres_val\n",
      "      \n",
      "misc.imsave('./thres_test/otsu_thres.jpeg', otsu_thres_img)\n",
      "#misc.imsave('./thres_test/adapt_thres.jpeg', adapt_thres_img)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The adpative threshold give far better distinction for the letters, particularly those in the marginalia, but there is a significant amount of noise. Trying again, adding in the wiener filter before thresholding. \n",
      "Steps 3.1 and 3.2 from the paper."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wien_img = signal.wiener(test_img)\n",
      "#wien_adapt_thres_img = threshold_adaptive(wien_img, 100)\n",
      "#misc.imsave('./thres_test/wien.jpeg', wien_img)\n",
      "#misc.imsave('./thres_test/wien_adapt_thres.jpeg', wien_adapt_thres_img)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This didn't have a massive effect itself, but given that there is so much noise using the adaptive filter, I'll also try using otsu's method, since this stage of thresholding is only meant to get a superset of foreground img pixels. \n",
      "\n",
      "The value it gives actualy doesn't quite threshold enough, i've just stuck a (+30) onto it just now, for the sake of getting the rest of the process written, but I think it would be best to come back and try using another thresholding method - particularly Sauvola's method which they're using in this paper. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wien_otsu_thres_val = threshold_otsu(wien_img)\n",
      "wien_otsu_thres_img = wien_img < otsu_thres_val\n",
      "misc.imsave('./thres_test/wien_otsu_thres.jpeg', wien_otsu_thres_img)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "3.3 Background surface estimation. \n",
      "Image saved seems to be normalised to a dark range "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now need to implement the following neighbouring pixel interpolation to fill in those areas:\n",
      "      \n",
      "$ B(x,y) = \\begin{cases} I(x,y) & if S(x, y) = 0 \\\\ \\sum^{x+dx}_{ix=x-dx} \\sum^{y+dy}_{iy=y-dy}(I(ix,iy)(1-S(ix,iy))) \\over \\sum^{x+dx}_{ix=x-dx}\\sum_{y+dy}^{iy=y-dy}(1-S(ix,iy) & if S(x, y) = 1\\\\ \\end{cases} $\n",
      "\n",
      "where $S(x,y)$ is the mask, $I(x,y)$ is the image, and $dx,dy$ is a interpolation window which in the paper is said should \\cover at least two image characters\\."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def neighbouring_pixel_interpolation(img, mask, window=28):\n",
      "    \"\"\" This is pretty slow still, might be worth looking into rewriting as a ufunc. \"\"\"\n",
      "    interpolated_img = np.zeros_like(img)\n",
      "    height, width = interpolated_img.shape \n",
      "    window = window / 2\n",
      "    # inverting this just now to avoid doing it for every window later. \n",
      "    mask = 1-mask\n",
      "          \n",
      "    def value_for_pixel(x, y):\n",
      "        # Because we're inverting the mask, 1 rather than 0.\n",
      "        if mask[x,y] == 1:\n",
      "            return img[x,y]\n",
      "        else:\n",
      "            img_window = img[x-window:x+window,y-window:y+window]\n",
      "            mask_window = mask[x-window:x+window,y-window:y+window]\n",
      "            res = np.sum(img_window*mask_window) / np.sum(mask_window)\n",
      "            # The following is a hack to get this working just now. \n",
      "            if np.isnan(res):\n",
      "                return 1\n",
      "            return res\n",
      "            \n",
      "    for i in range(height):\n",
      "        for j in range(width):\n",
      "            interpolated_img[i,j] = value_for_pixel(i,j)\n",
      "      \n",
      "    return interpolated_img\n",
      "          "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The implementation of the neighbouring pixel interpolation above is pretty poor, though I think that it works as expected having seen the results in the paper. Two things which seem to be particular issues are the resolution of the image, which makes the inpainting much more obvious, and the halo effect from the removal of the letters due to imperfect thresholding at the initial stage. \n",
      "      \n",
      "I'm going to re-implement the above using scipy.ndimage.filters.generic_filter, which i've just found, and then see if there is anything I can do using an inverse gaussian weighting (?) to take care of the halo effect and smooth out the results."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def neighbouring_pixel_interpolation2(img, mask):\n",
      "    \"\"\" Doesn't work, some fundamental issue with it \"\"\"\n",
      "    mask = 1-mask\n",
      "    combined_img = img*mask\n",
      "          \n",
      "    def NPI_filter(window):\n",
      "        window_mask = window.astype(bool).astype(int)\n",
      "        if window_mask[-1] == 0:\n",
      "            return np.sum(window)/ np.sum(mask)\n",
      "        else:\n",
      "            return window[-1]\n",
      "          \n",
      "    return ndimage.filters.generic_filter(combined_img, NPI_filter, mode='constant', cval=255, size=30, origin=(14,14))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The above implementation doesn't work at all as expected, and is (at times very) slow compared to the iteration method i'd previously written. Returning to fix the issues with it instead. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "int_mask = wien_otsu_thres_img.astype(int)\n",
      "inter_background = neighbouring_pixel_interpolation(wien_img, int_mask, window=10)\n",
      "misc.imsave('thres_test/interpolation.jpg', inter_background)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I'd attempted running a gaussian filter across the image below - realised that adding in anything like this to the interpolation function would require me to use pixels in the surrounding area. Think that there may still be something that could be done with a mask over the window being used in the interpolation function to get a bit more texture in the infill (i.e. sparse points from across the same area to make up the average rather than just the average.) \n",
      "\n",
      "The blur is alright, but not sure that it really adds anything, especially when the issue seems to be with the initial threshold rather than at this stage. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "blurred = gaussian_filter(inter_background, 5)\n",
      "misc.imsave('thres_test/blurred.jpg', blurred )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "3.4. Now implementing the actual binarisation step, which is defined as follows:\n",
      "\n",
      "$ T(x,y) = \\begin{cases} 1 & if B(x, y) - I(x,y) > d(B(x,y)), \\\\0 & otherwise \\\\ \\end{cases} $\n",
      "\n",
      "There are a few intermediary steps to get to that point though, the first of which is calculating the average distance between foreground and background as follows:\n",
      "\n",
      "$ \\delta = {\\sum_{x} \\sum_{y}(B(x,y) - I(x,y)) \\over \\sum_{x}\\sum_{y} (1-S(x,y) } $"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def fore_back_dist(background, img, mask):\n",
      "    return np.sum(background - img) / np.sum(mask)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dist = fore_back_dist(inter_background, wien_img, int_mask )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next is calculating the average of the background surface in the former text areas, defined as follows:\n",
      "\n",
      "$ b = { \\sum_{x} \\sum_{y}(B(x,y)(1-S(x,y)) \\over \\sum_{x}\\sum_{y} (1-S(x,y) } $"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def average_text_background(img, mask):\n",
      "    background_mask = 1 -mask\n",
      "    text_background = img * background_mask\n",
      "    return np.sum(text_background) / np.sum(background_mask)\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "avg_back = average_text_background(inter_background, int_mask)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 43
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now I need to implement the sigmoid function that forms a main part of the binarisation step:\n",
      "\n",
      "$ d(B(x,y)) = q\\delta \\left( { (1-p_2) \\over 1 + exp( {-4B(x,y) \\over b(1-p_1)} + {2(1+p_1)\\over (1-p_1)} ) } +p_2 \\right)$\n",
      "\n",
      "I don't really know what I should be calling this, because i'm not good at maths. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def magic_func(pixel, background, distance):\n",
      "    q = 0.6\n",
      "    p1 = 0.5\n",
      "    p2 = 0.8\n",
      "    aye = 2*(1+p1)/(1-p1)\n",
      "    naw = (-4 * pixel)/ background * (1-p1)\n",
      "    wit = 1 + np.exp(naw +aye)\n",
      "    jings = ((1-p2)/ wit) + p2\n",
      "    return q * distance * jings"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So finally now i'll implement the actual binarisation step, which was described above. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "binarised_img = np.zeros_like(wien_img)\n",
      "height, width = binarised_img.shape \n",
      "\n",
      "def bin_pixel(x, y):\n",
      "    img_pixel = wien_img[x,y]\n",
      "    back_pixel = inter_background[x,y]\n",
      "    if back_pixel - img_pixel > magic_func(back_pixel, avg_back, dist):\n",
      "        return False\n",
      "    else: \n",
      "        return True\n",
      "    \n",
      "for i in range(height):\n",
      "    for j in range(width):\n",
      "        binarised_img[i,j] = bin_pixel(i,j)\n",
      "\n",
      "misc.imsave('./thres_test/magic_bin.jpg', binarised_img)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 45
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The results are pretty decent on the full MSS image, though it's still having issues in areas where the page is particularly light, and in areas where the page is particularly dark. In VA013RN-0014.jpeg there are a number of dark smudges on the page, a couple of these _do_ almost completely obscure the writing, but a good number of them don't affect the readibility all that much. These dark smudges all come out as large black blobs with this method, this doesn't seem to be due to the initial otsu threshold, since they don't appear so much in this. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "3.5 The authors of the paper state that they achieved better results by incorporating upscaling into the binarisation step:\n",
      "\n",
      "$ T(x',y') = \\begin{cases} 1 & if B(x, y) - I_u(x',y') > d(B(x,y)), \\\\0 & otherwise \\\\ \\end{cases} $\n",
      "\n",
      "Where $T(x',y')$ is $M$ times the size of the original. They give a whole writeup of the approach, but from what they say it's really just bicubic interpolation used to scale up the image, which you should get access to through scipy.misc.imresize. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "big_wien_img = misc.imresize(wien_img, 200 ,interp='bicubic')\n",
      "misc.imsave('./thres_test/big_wien_img.jpg', big_wien_img)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "big_binarised_img = np.zeros_like(big_wien_img)\n",
      "height, width = big_binarised_img.shape \n",
      "def bin_pixel(x, y):\n",
      "    x_2 = int(x/2)\n",
      "    y_2 = int(y/2)\n",
      "    img_pixel = big_wien_img[x,y]\n",
      "    back_pixel = inter_background[x_2,y_2]\n",
      "    if back_pixel - img_pixel > magic_func(back_pixel, avg_back, dist):\n",
      "        return False\n",
      "    else: \n",
      "        return True\n",
      "for i in range(height):\n",
      "    for j in range(width):\n",
      "        big_binarised_img[i,j] = bin_pixel(i,j)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 54
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The above doesn't actually work - the values at each pixel in the scaled image seem to be substantially larger than the unscaled image, and as a result $ B(x,y) - I_u(x',y') $ always ends up negative, which must be some quirk of the scaling function. I will try again to implement it as in the paper (though I deleted my other attempt when I tried the scipy implementation.)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def eff(img, ex, m):\n",
      "    \"\"\" *Assuming* that this is correct just now. \"\"\"\n",
      "    x = int(ex/2)\n",
      "    a = (ex/2.0)-x\n",
      "    try:\n",
      "        one = (-a*(1-a)**2)*img[x-1,m]\n",
      "    except IndexError:\n",
      "        one = 255 \n",
      "    try:\n",
      "        two = (1-(2*(a**3))+a**3)*img[x,m]\n",
      "    except IndexError:\n",
      "        two = 255 \n",
      "    try:\n",
      "        three = (a*(1+a-(a**2)))*img[x+1,m]\n",
      "    except IndexError:\n",
      "        three = 255 \n",
      "    try:\n",
      "        four = ((a**2)*(1-a))*img[x+2,m]\n",
      "    except IndexError:\n",
      "        four = 255 \n",
      "    print(one,two,three,four)\n",
      "    return one + two + three + four\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 118
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def bicubic_pixel(ex, why, img):\n",
      "    y = int(why/2)\n",
      "    b = (why/2.0)-y\n",
      "    try:\n",
      "        one = (-b*(1-b)**2)*eff(img,ex,y-1)\n",
      "    except IndexError:\n",
      "        one = 255 \n",
      "    try:\n",
      "        two = (1-(2*(b**3))+b**3)*eff(img,ex,y)\n",
      "    except IndexError:\n",
      "        two = 255 \n",
      "    try:\n",
      "        three = (b*(1+b-(b**2)))*eff(img,ex,y+1)\n",
      "    except IndexError:\n",
      "        three = 255 \n",
      "    try:\n",
      "        four = ((b**2)*(1-b))*eff(img,ex,y+2)\n",
      "    except IndexError:\n",
      "        four = 255 \n",
      "    print(one,two,three,four)\n",
      "    return one + two + three + four\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 119
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "diy_big_wien = np.empty((800,800),dtype='float64')\n",
      "for i in range(799):\n",
      "    for j in range(799):\n",
      "        diy_big_wien[i,j] = bicubic_pixel(i,j, wien_img.astype(int))\n",
      "\n",
      "misc.imsave('./thres_test/diy_big_wien.jpg', diy_big_wien)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 106
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bicubic_pixel(0,1,wien_img)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(-0.0, 137.47542808806531, 0.0, 0.0)\n",
        "(-0.0, 221.54919169555387, 0.0, 0.0)\n",
        "(-0.0, 217.88469713557265, 0.0, 0.0)\n",
        "(-0.0, 221.05917488546663, 0.0, 0.0)\n",
        "(-17.184428511008164, 193.85554273360964, 136.17793570973291, 27.632396860683329)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 120,
       "text": [
        "340.48144679301777"
       ]
      }
     ],
     "prompt_number": 120
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bicubic_pixel(1,2,wien_img)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(-28.177577290405132, 193.85554273360964, 140.45675195502, 28.378253081253909)\n",
        "(-28.486948846081226, 190.64910999362607, 136.3266658782959, 27.31084696451823)\n",
        "(-28.516743991973659, 193.42677802478329, 135.30805481804742, 27.004249784681534)\n",
        "(-28.401183057284811, 193.46529794272902, 138.34201282925076, 27.437888675265842)\n",
        "(-0.0, 325.799673990359, 0.0, 0.0)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 123,
       "text": [
        "325.799673990359"
       ]
      }
     ],
     "prompt_number": 123
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 124,
       "text": [
        "[array([[2]]), array([[2]])]"
       ]
      }
     ],
     "prompt_number": 124
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}