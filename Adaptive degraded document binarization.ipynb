{
 "metadata": {
  "name": "",
  "signature": "sha256:2820a123e156f09ce4376c24a5efa42e78e48d776217890510c08bd75bd065d0"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Trying to replicate the algorithm described in:\n",
      "\n",
      "[1]B. Gatos, I. Pratikakis, and S. J. Perantonis, \"Adaptive degraded document image binarization\", Pattern Recognition, vol. 39, no. 3, pp. 317\\u2013327, Mar. 2006."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy import misc\n",
      "from scipy import signal\n",
      "from scipy import ndimage\n",
      "from skimage.filter import *\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_img_path = './test_pages/original/VA013RN-0014.jpeg'\n",
      "# flatten=True converts to greyscale when reading img in. \n",
      "test_img = misc.imread(test_img_path, flatten=True)\n",
      "#test_img = test_img[400:800,400:800]\n",
      "misc.imsave('./thres_test/original.jpeg', test_img)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Tests of the skimage otsu and adaptive thresholds"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "adapt_thres_img = threshold_adaptive(test_img, 47)\n",
      "otsu_thres_val = threshold_otsu(test_img)\n",
      "otsu_thres_img = test_img > otsu_thres_val\n",
      "      \n",
      "misc.imsave('./thres_test/otsu_thres.jpeg', otsu_thres_img)\n",
      "misc.imsave('./thres_test/adapt_thres.jpeg', adapt_thres_img)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The adpative threshold give far better distinction for the letters, particularly those in the marginalia, but there is a significant amount of noise. Trying again, adding in the wiener filter before thresholding. \n",
      "Steps 3.1 and 3.2 from the paper."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wien_img = signal.wiener(test_img)\n",
      "wien_adapt_thres_img = threshold_adaptive(wien_img, 100)\n",
      "misc.imsave('./thres_test/wien.jpeg', wien_img)\n",
      "misc.imsave('./thres_test/wien_adapt_thres.jpeg', wien_adapt_thres_img)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This didn't have a massive effect itself, but given that there is so much noise using the adaptive filter, I'll also try using otsu's method, since this stage of thresholding is only meant to get a superset of foreground img pixels."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wien_otsu_thres_val = threshold_otsu(wien_img)\n",
      "wien_otsu_thres_img = wien_img > otsu_thres_val +30\n",
      "misc.imsave('./thres_test/wien_otsu_thres.jpeg', wien_otsu_thres_img)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "3.3 Background surface estimation. \n",
      "Image saved seems to be normalised to a dark range "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "aye = np.zeros_like(wien_img)\n",
      "aye.fill(255)\n",
      "      \n",
      "masked_background = np.where(wien_otsu_thres_img, wien_img, aye)\n",
      "misc.imsave('./thres_test/wien_otsu_mask.jpeg', masked_background.astype(int))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The above just removes the characters though, need to implement the following neighbouring pixel interpolation to fill in those areas:\n",
      "      \n",
      "$ B(x,y) = \\begin{cases} I(x,y) & if S(x, y) = 0 \\\\ \\sum^{x+dx}_{ix=x-dx} \\sum^{y+dy}_{iy=y-dy}(I(ix,iy)(1-S(ix,iy))) \\over \\sum^{x+dx}_{ix=x-dx}\\sum_{y+dy}^{iy=y-dy}(1-S(ix,iy) & if S(x, y) = 1\\\\ \\end{cases} $\n",
      "\n",
      "where $S(x,y)$ is the mask, $I(x,y)$ is the image, and $dx,dy$ is a interpolation window which in the paper is said should \\cover at least two image characters\\."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def neighbouring_pixel_interpolation(img, mask, window=28):\n",
      "\n",
      "    interpolated_img = np.zeros_like(img)\n",
      "    height, width = interpolated_img.shape \n",
      "    window = window / 2\n",
      "          \n",
      "    def value_for_pixel(x, y):\n",
      "        if mask[x,y] == 0:\n",
      "            return img[x,y]\n",
      "        else:\n",
      "            img_window = img[x-window:x+window,y-window:y+window]\n",
      "            mask_window = 1 - mask[x-window:x+window,y-window:y+window]\n",
      "            top = np.sum(img_window*mask_window)\n",
      "            bottom = np.sum(mask_window)\n",
      "            \n",
      "            res =  top / bottom\n",
      "            # The following is a hack to get this working just now. \n",
      "            if np.isnan(res):\n",
      "                return 1\n",
      "            return res\n",
      "            \n",
      "    for i in range(height):\n",
      "        for j in range(width):\n",
      "            interpolated_img[i,j] = value_for_pixel(i,j)\n",
      "      \n",
      "    return interpolated_img\n",
      "          "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The implementation of the neighbouring pixel interpolation above is pretty poor, though I think that it works as expected having seen the results in the paper. Two things which seem to be particular issues are the resolution of the image, which makes the inpainting much more obvious, and the halo effect from the removal of the letters due to imperfect thresholding at the initial stage. \n",
      "      \n",
      "I'm going to re-implement the above using scipy.ndimage.filters.generic_filter, which i've just found, and then see if there is anything I can do using an inverse gaussian weighting (?) to take care of the halo effect and smooth out the results."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def neighbouring_pixel_interpolation2(img, mask):\n",
      "    \"\"\" Doesn't work, some fundemental issue with it \"\"\"\n",
      "    mask = 1-mask\n",
      "    combined_img = img*mask\n",
      "          \n",
      "    def NPI_filter(window):\n",
      "        window_mask = window.astype(bool).astype(int)\n",
      "        if window_mask[-1] == 0:\n",
      "            return np.sum(window)/ np.sum(mask)\n",
      "        else:\n",
      "            return window[-1]\n",
      "          \n",
      "    return ndimage.filters.generic_filter(combined_img, NPI_filter, mode='constant', cval=255, size=30, origin=(14,14))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The above implementation doesn't work at all as expected, and is (at times very) slow compared to the iteration method i'd previously written. Returning to fix the issues with it instead. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bin_arr = np.invert(wien_otsu_thres_img).astype(int)\n",
      "first_imp = neighbouring_pixel_interpolation(wien_img, bin_arr, window=48)\n",
      "misc.imsave('thres_test/interpolation.jpg', first_imp)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:16: RuntimeWarning: invalid value encountered in double_scalars\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "blurred = gaussian_filter(first_imp, 5)\n",
      "misc.imsave('thres_test/blurred.jpg', blurred )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "zoom_in = ndimage.interpolation.zoom(wien_img,0.5)\n",
      "misc.imsave('thres_test/zoom_in.jpg', zoom_in )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "zoom_otsu_thres_val = threshold_otsu(zoom_in)\n",
      "zoom_otsu_thres_img = zoom_in > zoom_otsu_thres_val\n",
      "misc.imsave('./thres_test/zoom_otsu_thres.jpeg', zoom_otsu_thres_img)\n",
      "zoom_bin_arr = np.invert(zoom_otsu_thres_img).astype(int)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "first_imp = neighbouring_pixel_interpolation(zoom_in, zoom_bin_arr, window=48)\n",
      "misc.imsave('thres_test/zoom_interpolation.jpg', first_imp)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "zoom_first_imp = ndimage.interpolation.zoom(first_imp,2)\n",
      "misc.imsave('thres_test/zoom_back_interpolation.jpg', zoom_first_imp)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "zoom_2_otsu_thres_val = threshold_otsu(zoom_first_imp)\n",
      "zoom_2_otsu_thres_img = zoom_first_imp > zoom_2_otsu_thres_val -25\n",
      "misc.imsave('./thres_test/zoom_2_otsu_thres.jpeg', zoom_2_otsu_thres_img)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "zoom_2_bin_arr = np.invert(zoom_2_otsu_thres_img).astype(int)\n",
      "second_imp = neighbouring_pixel_interpolation(zoom_first_imp, zoom_2_bin_arr, window=48)\n",
      "misc.imsave('thres_test/zoom_2_interpolation.jpg', second_imp)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}